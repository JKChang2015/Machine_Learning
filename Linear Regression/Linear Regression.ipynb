{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "<br/>\n",
    "\n",
    "linear regression is a linear approach for **modelling** the relationship between a scalar **dependent variable y** and one or more **independent variables denoted X**. Using exsting data to estimate unknown data.\n",
    "\n",
    "Linear regression model assumes that the relationship between the dependent variable **yi** and the p-vector of regressors **xi** is linear.\n",
    "\n",
    "$$y_{i} = \\beta _{0}1 + \\beta _{1}x_{i1} + ... + \\beta _{p}x_{ip} + \\varepsilon _{i} = x_{i}^{T}\\beta + \\varepsilon _{i}$$\n",
    "\n",
    "where $^{T}$ denotes the transpose, so that $x_{i}^{T}$ is the inner product between vectors $x_{i}$ and C. The equation can stacked together and written in vector form as:\n",
    "$$ y = X\\beta + \\varepsilon $$\n",
    "where,<br/>\n",
    "$ y=\\begin{pmatrix} y_{1}\\\\ y_{2}\\\\ ...\\\\ y_{n} \\end{pmatrix} $ ,\n",
    "$X=\\begin{pmatrix} x_{1}^{T}\\\\  x_{2}^{T}\\\\ ...\\\\ x_{n}^{T}\\end{pmatrix}\n",
    "=\\begin{pmatrix} \n",
    " 1 &x _{11} & ... &x _{1p} \\\\ \n",
    " 1& x _{21} & ... & x _{2p}\\\\ \n",
    " ...& ... & ... & ...\\\\ \n",
    " 1&  x _{n1}& ... & x _{np}\n",
    "\\end{pmatrix}$ , <br/>\n",
    "$\\beta  = \\begin{pmatrix} \\beta _{0}\\\\ \\beta _{1}\\\\ \\beta _{2}\\\\ ...\\\\ \\beta _{p} \\end{pmatrix}$ , and\n",
    "$\\varepsilon = \\begin{pmatrix} \\varepsilon _{0}\\\\ \\varepsilon _{1}\\\\ ...\\\\ \\varepsilon _{n} \\end{pmatrix}$\n",
    "\n",
    "- $y_{i}$ is called dependent variable. \n",
    "- $x_{i}$ is called independent variable. \n",
    "- $\\beta$ is called intercept, a (p+1)-dimension **parameter vector**, where $\\beta _{0}$ is the constant (offset) term.  Its elements are also called effects, and the estimates of it are called \"estimated effects\" or regression coefficients. \n",
    "- $\\varepsilon _{i}$ is called the _error term_ or _disturbance term_.which is diffence between estimate value $y_{i}$ and real value $x_{i}\\beta$,  $$\\varepsilon _{i} = y_{i} - x_{i}\\beta$$\n",
    "  1. they are independently\n",
    "  2. they are normal distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability density function:\n",
    "$$p(\\varepsilon _{i}) = \\frac{1}{\\sqrt{2\\pi \\sigma  ^{2}}} exp(-\\frac{\\varepsilon _{i}^{2}}{2\\sigma  ^{2}})$$\n",
    "$$\\Rightarrow p(y_{i}|x_{i},\\beta) = \\frac{1}{\\sqrt{2\\pi \\sigma^{2}}} exp(-\\frac{(y_{i}-x_{i}\\beta)^{2}}{2\\sigma  ^{2}})$$\n",
    "\n",
    "#### Likelihood estimationï¼šusing data to esitimate function paramters to let argmin($\\varepsilon$)\n",
    "$$Likelihood(\\beta ) = \\prod_{i=1}^{m}p(y_{i}|x_{i},\\beta) =\\prod_{i=1}^{m} \\frac{1}{\\sqrt{2\\pi \\sigma^{2}}} exp(-\\frac{(y_{i}-x_{i}\\beta)^{2}}{2\\sigma  ^{2}})$$\n",
    "\n",
    "#### Logarithm likelihood estimation\n",
    "$$log\\,  L(\\beta ) = log\\, \\prod_{i=1}^{m} \\frac{1}{\\sqrt{2\\pi \\sigma^{2}}} exp(-\\frac{(y_{i}-x_{i}\\beta)^{2}}{2\\sigma  ^{2}})$$\n",
    "$$=\\sum_{i=1}^{m} log\\, \\frac{1}{\\sqrt{2\\pi \\sigma^{2}}} exp(-\\frac{(y_{i}-x_{i}\\beta)^{2}}{2\\sigma  ^{2}})$$\n",
    "$$= m\\, log\\, \\frac{1}{\\sqrt{2\\pi \\sigma^{2}}} - \\frac{1}{\\sigma^{2}}\\cdot \\frac{1}{2}\\sum_{i=1}^{m}(y_{i}-x_{i}\\beta)^{2}$$\n",
    "\n",
    "#### Least squares\n",
    "$$J(\\beta ) = \\frac{1}{2}\\sum_{i=1}^{m}(y_{i}-x_{i}\\beta)^{2}$$\n",
    "\n",
    "#### objective function\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    " J(\\beta )&= \\frac{1}{2}\\sum_{i=1}^{m}(x_{i}\\beta-y_{i})^{2}   \\\\\n",
    "          &= \\frac{1}{2}(X\\beta -y)^{T}(X\\beta -y) \\\\\n",
    "          &= \\frac{1}{2}(\\beta ^{T}X ^{T} - y ^{T})(X\\beta -y) \\\\\n",
    "          &= \\frac{1}{2}(\\beta ^{T}X ^{T}X\\beta -\\beta ^{T}X ^{T}y- y ^{T}X\\beta+y ^{T}y) \\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "#### partial derivatives $\\triangledown_{\\beta} J(\\beta)$\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    " \\triangledown_{\\beta } J(\\beta ) &=\\triangledown_{\\beta } (\\frac{1}{2}(\\beta ^{T}X ^{T}X\\beta -\\beta ^{T}X ^{T}y- y ^{T}X\\beta+y ^{T}y)) \\\\\n",
    "&=  \\frac{1}{2}(2X ^{T}X\\beta - X ^{T}y - (y^{T}X)^{T}) \\\\\n",
    "&= X^{T}X\\beta - X^{T}y\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "when $\\triangledown_{\\beta} J(\\beta) = 0$:\n",
    "$$\\beta = (X^{T}X)^{-1}\\,X^{T}y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation:\n",
    "In statistics, the coefficient of determination, denoted R2 or r2 and pronounced \"R squared\", is the proportion of the variance in the dependent variable that is predictable from the independent variable(s)\n",
    "\n",
    "$$R^{2} : 1 - \\frac{\\sum_{i=1}^{m}(\\hat{y_{i}}-y_{i})^{2}}{\\sum_{i=1}^{m}(y_{i} - \\overline{y})^{2}}$$\n",
    "\n",
    "where, <br\\>\n",
    "$\\hat{y_{i}}$ is estimated y <br\\>\n",
    "$\\overline{y}$ is mean y\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
