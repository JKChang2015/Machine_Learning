{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial neural networks (ANNs) are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Such systems \"learn\" tasks by considering examples, generally without task-specific programming. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as \"cat\" or \"no cat\" and using the results to identify cats in other images. They do this without any a priori knowledge about cats, e.g., that they have fur, tails, whiskers and cat-like faces. Instead, they evolve their own set of relevant characteristics from the learning material that they process.\n",
    "\n",
    "An ANN is based on a collection of connected units or nodes called artificial neurons. Each connection (a simplified version of a synapse) between artificial neurons can transmit a signal from one to another. The artificial neuron that receives the signal can process it and then signal artificial neurons connected to it.\n",
    "\n",
    "\n",
    "In common ANN implementations, the signal at a connection between artificial neurons is a real number, and the output of each artificial neuron is calculated by a non-linear function of the sum of its inputs. Artificial neurons and connections typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that only if the aggregate signal crosses that threshold is the signal sent. Typically, artificial neurons are organized in layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first (input), to the last (output) layer, possibly after traversing the layers multiple times.<br/><br/>\n",
    "\n",
    "CIFAR-10: https://www.cs.toronto.edu/~kriz/cifar.html <br/>\n",
    "10 tags, 50,000 training data, 10,000 testing data, size are 32*32<br/> \n",
    "Tags: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear loss function\n",
    "\n",
    "Linear classification function:   $$f(x,W) = Wx+b$$  <br/>\n",
    "Linear Loss function:\n",
    "$$L = \\frac{1}{N}\\sum_{i=1}^{N}\\sum_{j\\neq y_{i}}^{ } max(0,f(x_{i};W)_{j} -f(x_{i};W)_{y_{i}} + 1 )$$\n",
    "Average value of all sample training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalty function\n",
    "Penalty methods are a certain class of algorithms for solving constrained optimization problems.\n",
    "\n",
    "A penalty method replaces a constrained optimization problem by a series of unconstrained problems whose solutions ideally converge to the solution of the original constrained problem. The unconstrained problems are formed by adding a term, called a penalty function, to the objective function that consists of a penalty parameter multiplied by a measure of violation of the constraints. The measure of violation is nonzero when the constraints are violated and is zero in the region where constraints are not violated.\n",
    "\n",
    "$$L = \\frac{1}{N}\\sum_{i=1}^{N}\\sum_{j\\neq y_{i}}^{ } max(0,f(x_{i};W)_{j} -f(x_{i};W)_{y_{i}} + 1 ) + \\lambda R(W)$$\n",
    "where, <br/>\n",
    "R(W) is the regular pennalty (L2)\n",
    "$$R(W) = \\sum_{k}^{ }\\sum_{l}^{ }w_{k,l}^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "* SVM: Scoring result,\n",
    "* Softmax: Probability\n",
    "\n",
    "In mathematics, the softmax function, or normalized exponential function,is a generalization of the logistic function that \"squashes\" a K-dimensional vector `z`  of arbitrary real values to a K-dimensional vector $\\sigma (z)$ of real values in the range (0, 1) that add up to 1. The function is given by\n",
    "$$\\sigma :\\mathbb {R} ^{K}\\to (0,1)^{K}$$\n",
    "$$\\sigma (\\mathbf {z} )_{j}={\\frac {e^{z_{j}}}{\\sum _{k=1}^{K}e^{z_{k}}}}$$\n",
    "where, j = 1, …, K\n",
    "<br/><br/>\n",
    "\n",
    "In probability theory, the output of the softmax function can be used to represent a categorical distribution – that is, a probability distribution over K different possible outcomes. In fact, it is the gradient-log-normalizer of the categorical probability distribution.\n",
    "\n",
    "<br/>\n",
    "The softmax function is used in various multiclass classification methods, such as multinomial logistic regression (also known as softmax regression).multiclass linear discriminant analysis, naive Bayes classifiers, and artificial neural networks.\n",
    "\n",
    "<br/>\n",
    "Specifically, in multinomial logistic regression and linear discriminant analysis, the input to the function is the result of K distinct linear functions, and the predicted probability for the j'th class given a sample vector x and a weighting vector w is:\n",
    "\n",
    "$${\\displaystyle P(y=j\\mid \\mathbf {x} )={\\frac {e^{\\mathbf {x} ^{\\mathsf {T}}\\mathbf {w} _{j}}}{\\sum _{k=1}^{K}e^{\\mathbf {x} ^{\\mathsf {T}}\\mathbf {w} _{k}}}}}$$\n",
    "\n",
    "<br/>\n",
    "This can be seen as the composition of K linear functions $ \\mathbf {x} \\mapsto \\mathbf {x} ^{\\mathsf {T}}\\mathbf {w} _{1},\\ldots$ , $\\mathbf {x} \\mapsto \\mathbf {x} ^{\\mathsf {T}}\\mathbf {w} _{K}$ and the softmax function (where \n",
    "$\\mathbf {x} ^{\\mathsf {T}}\\mathbf {w}$  denotes the inner product of $\\mathbf {x}$  and $\\mathbf {w}$ ). The operation is equivalent to applying a linear operator defined by $\\mathbf {w}$ to vectors $\\mathbf {x}$, thus transforming the original, probably highly-dimensional, input to vectors in a K-dimensional space ${\\displaystyle \\mathbb {R} ^{K}}$.\n",
    "<br/><br/>\n",
    "#### loss function for softmax: using correct answers to calculate the log value\n",
    "$$L_{i} = log({\\frac {e^{sz_{j}}}{\\sum _{k=1}^{K}e^{z_{k}}}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network Optimization Algorithms\n",
    "<br/>\n",
    "<img src=\"./resources/machinelearningmodel.png\" style=\"width:800px;\"/>\n",
    "<br/>\n",
    "\n",
    "On this picture we can detect the following components: <br/>\n",
    "1. Training dataset: Basically a high speed disk containing your training data\n",
    "2. Batch of samples: A list of pairs (X,Y), consisting on inputs, expected outputs, for example X can be a image and Y the label \"cat\"\n",
    "3. Parameters: Set of parameters used by your model layers, to map X to Y\n",
    "4. Model: Set of computing layers that transform an input X and weights W, into a score (probable Y)\n",
    "5. Loss function: Responsible to say how far our score is from the ideal response Y, the output of the loss function is a scalar. Another way is also to consider that the loss function say how bad is your current set of parameters W.\n",
    "\n",
    "<br/>\n",
    "`forward-propagation:` from w to the result Loss function<br/>\n",
    "`back-propagation:` from Loss function back to w (red line)\n",
    "\n",
    "<img src=\"./resources/backprogration.png\" style=\"width:800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back propagation\n",
    "On the picture bellow we get a node f(x,y) that compute some function with two inputs x,y and output z. Now on the right side, we have this same node receiving from somewhere (loss function) a gradient dL/dz which means. \"How much L will change with a small change on z\". As the node has 2 inputs it will have 2 gradients. One showing how L will a small change dx and the other showing how L will change with a small change (dz) <br/><br/>\n",
    "\n",
    "<img src=\"./resources/chainrule_example.png\" style=\"width:800px;\"/>\n",
    "\n",
    " <br/>\n",
    "In order to calculate the gradients we need the input dL/dz (dout), and the derivative of the function f(x,y), at that particular input, then we just multiply them. Also we need the previous cached input, saved during forward propagation.\n",
    "<img src=\"./resources/back propagation in CNN.png\" style=\"width:800px;\"/>\n",
    " <br/> <br/> <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back propagation examples\n",
    "<br/> <br/>\n",
    "#### simple example\n",
    " <img src=\"./resources/SimpleGraph.png\" style=\"width:800px;\"/>\n",
    " <br/> <br/>\n",
    "1. Start from output node f, and consider that the gradient of f related to some criteria is 1 (dout)\n",
    "2. dq=(dout(1) * z), which is -4 (How the output will change with a change in q)\n",
    "3. dz=(dout(1) * q), which is 3 (How the output will change with a change in z)\n",
    "4. The sum gate distribute it's input gradients, so dx=-4, dy=-4 (How the output will change with x,z)\n",
    " <br/> <br/>\n",
    " \n",
    "#### Perceptron with 2 inputs\n",
    "This following graph represent the forward propagation of a simple 2 inputs, neural network with one output layer with sigmoid activation.<br/>\n",
    "sigmoid function: $$\\sigma (x) = \\frac{1}{1+e^{-x}}$$<br/><br/>\n",
    "$$f(w,x) = \\frac{1}{1+e^{-(w_{0}x_{0}+ w_{1}x_{1}+w_{2})}}$$\n",
    " <br/> <br/>\n",
    " <img src=\"./resources/SimplePerceptron.png\" style=\"width:300px;\"/>\n",
    " <img src=\"./resources/StepByStepExample.png\" style=\"width:800px;\"/>\n",
    "  <br/> <br/>\n",
    " \n",
    "1. Start from the output node, considering that or error(dout) is 1\n",
    "2. The gradient of the input of the 1/x will be -1/(1.37^2), -0.53\n",
    "3. The increment node does not change the gradient on it's input, so it will be (-0.53 * 1), -0.53\n",
    "4. The exp node input gradient will be (exp(-1(cached input)) * -0.53), -0.2\n",
    "5. The negative gain node will be it's input gradient (-1 * -0.2), 0.2\n",
    "6. The sum node will distribute the gradients, so, dw2=0.2, and the sum node also 0.2\n",
    "7. The sum node again distribute the gradients so again 0.2\n",
    "8. dw0 will be (0.2 * -1), -0.2\n",
    "9. dx0 will be (0.2 * 2). 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic blocks\n",
    "<br/>\n",
    "Some examples of basic blocks are, add, multiply, exp, max. All we need to do is observe their forward and backward calculation:<br/><br/>\n",
    " <img src=\"./resources/SumGate.png\" style=\"width:600px;\"/> <br/>\n",
    "  <img src=\"./resources/MulGate.png\" style=\"width:600px;\"/><br/>\n",
    "   <img src=\"./resources/MaxGate.png\" style=\"width:600px;\"/><br/>\n",
    "    <img src=\"./resources/GradientBranches.png\" style=\"width:600px;\"/>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neuron\n",
    "<br/>\n",
    " <img src=\"./resources/neuron_model.jpg\" style=\"width:700px;\"/> <br/><br/>\n",
    "The single artificial neuron will do a dot product between w and x, then add a bias, the result is passed to an activation function that will add some non-linearity. The neural network will be formed by those artificial neurons.<br/>\n",
    "The non-linearity will allow different variations of an object of the same class to be learned separately. Which is a different behaviour compared to the linear classifier that tries to learn all different variations of the same class on a single set of weights. More neurons and more layers is always better but it will need more data to train.<br/>\n",
    "Each layer learn a concept, from it's previous layer. So it's better to have deeper neural networks than a wide one. <br/> <br/><br/> \n",
    "\n",
    "### Neural networks as computation graphs\n",
    "<br/>\n",
    " <img src=\"./resources/NeuralNetworkGraph.png\" style=\"width:700px;\"/> <br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "<br/>\n",
    "After the neuron do the dot product between it's inputs and weights, it also apply a non-linearity on this result. This non-linear function is called Activation Function.On the past the popular choice for activation functions were the sigmoid and tanh. Recently it was observed the `ReLU` layers has better response for deep neural networks, due to a problem called vanishing gradient. So you can consider using only ReLU neurons.<br/><br/>\n",
    " <img src=\"./resources/ActivationFunctions.png\" style=\"width:700px;\"/> <br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization \n",
    "\n",
    "* If you initialize your weights to zero, your gradient descent will never converge<br/>\n",
    " <img src=\"./resources/all_zeros_initialization.png\" style=\"width:700px;\"/> <br/>\n",
    "\n",
    "\n",
    "* Initialize with small values<br/>\n",
    "Here randn gives random data with zero mean, unit standard deviation. are the number of input and outputs. The 0.01 term will keep the random weights small and close to zero.<br/>\n",
    "<img src=\"./resources/matlab_randn.png\" style=\"width:700px;\"/> <br/>\n",
    "\n",
    "The problem with the previous way to do initialization is that the variance of the outputs will grow with the number of inputs. To solve this issue we can divide the random term by the square root of the number of inputs.<br/>\n",
    "<img src=\"./resources/xavier_inits.png\" style=\"width:700px;\"/> <br/>\n",
    "\n",
    "\n",
    "Now it seems that we don't have dead neurons, the only problem with this approach is to use it with Relu neurons.<br/>\n",
    "<img src=\"./resources/xavier_inits_relu.png\" style=\"width:700px;\"/> <br/>\n",
    "\n",
    "To solve this just add a simple (divide by 2) term....<br/>\n",
    "<img src=\"./resources/xavier_inits_relu_fix.png\" style=\"width:700px;\"/> <br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "<br/>\n",
    "Dropout is a technique used to improve over-fit on neural networks, you should use Dropout along with other techniques like L2 Regularization. <br/>\n",
    "Basically during training half of neurons on a particular layer will be deactivated. This improve generalization because force your layer to learn with different neurons the same \"concept\".During the prediction phase the dropout is deactivated.\n",
    "\n",
    "<img src=\"./resources/dropout.jpg\" style=\"width:700px;\"/> <br/><br/>\n",
    "Bellow we have a classification error (Not including loss), observe that the test/validation error is smaller using dropout\n",
    "<img src=\"./resources/With_Without_Dropout.png\" style=\"width:700px;\"/> <br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
