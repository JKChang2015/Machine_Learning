{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "A `decision tree` is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including `chance event outcomes`, `resource costs`, and `utility`. It is one way to display an algorithm that only contains conditional control statements. <br/> <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy\n",
    "The most general interpretation of entropy is as a measure of our `uncertainty` about a stochastic variable.\n",
    "Information entropy is defined as the average amount of information produced by a `stochastic` source of data.\n",
    "\n",
    "Specifically, entropy is a logarithmic measure of the number of states with significant probability of being occupied:\n",
    "$$ H(X)=-\\sum _{i}p_{i}\\log p_{i} $$\n",
    "where,<br/>\n",
    "$p_{i}$ is the `probability` that the system is in the i-th microstate.This definition assumes that the basis set of states has been picked so that there is no information on their relative phases. In a different basis set, the more general expression is.\n",
    "\n",
    "In decision tree, entropy is applied to determine the pattern using for each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART (Classification And Regression Tree)\n",
    "Algorithms for constructing decision trees usually work top-down, by choosing a variable at each step that best splits the set of items. Different algorithms use different metrics for measuring \"best\". These generally measure the homogeneity of the target variable within the subsets. <br/> <br/> \n",
    "\n",
    "#### Gini impurity\n",
    "Used by the `CART` algorithm, Gini impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset. Gini impurity can be computed by summing the probability $p_{i}$ of an item with label i being chosen times the probability $\\sum _{k\\neq i}p_{k}=1-p_{i}$ of a mistake in categorizing that item. It reaches its minimum (zero) when all cases in the node fall into a single target category.\n",
    "$$  I_{G}(p)=\\sum _{i=1}^{J}p_{i}\\sum _{k\\neq i}p_{k}=\\sum _{i=1}^{J}p_{i}(1-p_{i})=\\sum _{i=1}^{J}(p_{i}-{p_{i}}^{2})=\\sum _{i=1}^{J}p_{i}-\\sum _{i=1}^{J}{p_{i}}^{2}=1-\\sum _{i=1}^{J}{p_{i}}^{2} $$\n",
    "\n",
    "<br/>\n",
    "#### Variance reduction\n",
    "variance reduction is often employed in cases where the target variable is continuous (regression tree), meaning that use of many other metrics would first require discretization before being applied. The variance reduction of a node N is defined as the total reduction of the variance of the target variable x due to the split at this node:\n",
    "$$I_{V}(N)={\\frac {1}{|S|^{2}}}\\sum _{i\\in S}\\sum _{j\\in S}{\\frac {1}{2}}(x_{i}-x_{j})^{2}-\\left({\\frac {1}{|S_{t}|^{2}}}\\sum _{i\\in S_{t}}\\sum _{j\\in S_{t}}{\\frac {1}{2}}(x_{i}-x_{j})^{2}+{\\frac {1}{|S_{f}|^{2}}}\\sum _{i\\in S_{f}}\\sum _{j\\in S_{f}}{\\frac {1}{2}}(x_{i}-x_{j})^{2}\\right)$$\n",
    "\n",
    "where, <br/>\n",
    "$S$, $S_{t}$ and $S_{f}$ are the set of presplit sample indices, set of sample indices for which the split test is true, and set of sample indices for which the split test is false, respectively. Each of the above summands are indeed variance estimates, though, written in a form without directly referring to the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
